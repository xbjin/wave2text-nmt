01/02 16:22:25 /home/chengzhu/work/seq2seq/translate/__main__.py experiments/ted_speech/baseline.yaml --train -v
01/02 16:22:25 commit hash 3bb93835464de375e54d06f6c089c0f9a69774d6
01/02 16:22:25 program arguments
01/02 16:22:25   allow_growth         True
01/02 16:22:25   attention            True
01/02 16:22:25   auxiliary_score_function None
01/02 16:22:25   batch_size           4
01/02 16:22:25   beam_size            1
01/02 16:22:25   checkpoints          []
01/02 16:22:25   dropout_rate         0.5
01/02 16:22:25   embedding_prefix     'vectors'
01/02 16:22:25   ensemble             False
01/02 16:22:25   feed_previous        0.0
01/02 16:22:25   freeze_variables     []
01/02 16:22:25   gpu_id               0
01/02 16:22:25   keep_best            4
01/02 16:22:25   len_normalization    1.0
01/02 16:22:25   lm_weight            0.2
01/02 16:22:25   log_file             'experiments/ted_speech/baseline/log.txt'
01/02 16:22:25   max_dev_size         0
01/02 16:22:25   max_gradient_norm    5.0
01/02 16:22:25   max_input_len        600
01/02 16:22:25   max_steps            20000
01/02 16:22:25   max_train_size       0
01/02 16:22:25   mem_fraction         1.0
01/02 16:22:25   model_dir            'experiments/ted_speech/baseline'
01/02 16:22:25   no_gpu               False
01/02 16:22:25   num_samples          512
01/02 16:22:25   optimizer            'adam'
01/02 16:22:25   output               None
01/02 16:22:25   remove_unk           False
01/02 16:22:25   score_function       'bleu_score'
01/02 16:22:25   script_dir           'scripts'
01/02 16:22:25   steps_per_checkpoint 1
01/02 16:22:25   steps_per_eval       1
01/02 16:22:25   tasks               
[{'data_dir': 'experiments/ted_speech/data',
  'decoder': {'attention_filter_length': 0,
              'attention_filters': 0,
              'attention_window_size': 0,
              'bidir': True,
              'binary': False,
              'cell_size': 256,
              'character_level': False,
              'dynamic': None,
              'embedding_size': 256,
              'input_layers': [],
              'layers': 2,
              'load_embeddings': [],
              'name': 'en',
              'parallel_iterations': 32,
              'pooling_avg': False,
              'residual_connections': False,
              'swap_memory': True,
              'time_pooling': None,
              'use_lstm': True,
              'vocab_size': 124},
  'dev_prefix': ['dev'],
  'encoders': [{'attention_filter_length': 25,
                'attention_filters': 1,
                'attention_window_size': 0,
                'bidir': True,
                'binary': True,
                'cell_size': 256,
                'character_level': False,
                'dynamic': None,
                'embedding_size': 41,
                'input_layers': [256, 256],
                'layers': 3,
                'load_embeddings': [],
                'name': 'feats41',
                'parallel_iterations': 32,
                'pooling_avg': True,
                'residual_connections': False,
                'swap_memory': True,
                'time_pooling': [2, 2],
                'use_lstm': True,
                'vocab_size': 0}],
  'learning_rate': 0.001,
  'learning_rate_decay_factor': 0.99,
  'lm_file': None,
  'max_output_len': 25,
  'name': 'main',
  'ratio': 1.0,
  'train_prefix': 'train',
  'vocab_prefix': 'vocab'}]
01/02 16:22:25 creating model
01/02 16:22:25 using device: None
01/02 16:22:25 reading vocabularies
01/02 16:22:25 creating model main
01/02 16:22:34 model parameters (98)
01/02 16:22:34   seq2seq/learning_rate:0 ()
01/02 16:22:34   seq2seq/global_step:0 ()
01/02 16:22:34   seq2seq/dropout_keep_prob:0 ()
01/02 16:22:34   seq2seq/multi_encoder/feats41/input_layer_0/Matrix:0 (41, 256)
01/02 16:22:34   seq2seq/multi_encoder/feats41/input_layer_0/Bias:0 (256,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/input_layer_1/Matrix:0 (256, 256)
01/02 16:22:34   seq2seq/multi_encoder/feats41/input_layer_1/Bias:0 (256,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Matrix:0 (512, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Matrix:0 (512, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Matrix:0 (768, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Matrix:0 (768, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Matrix:0 (768, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Matrix:0 (768, 1024)
01/02 16:22:34   seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/multi_encoder/feats41/bidir_projection/Matrix:0 (512, 256)
01/02 16:22:34   seq2seq/embedding_en:0 (124, 256)
01/02 16:22:34   seq2seq/decoder_en/initial_state_projection/Matrix:0 (1536, 1024)
01/02 16:22:34   seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Matrix:0 (512, 1024)
01/02 16:22:34   seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Matrix:0 (512, 1024)
01/02 16:22:34   seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Bias:0 (1024,)
01/02 16:22:34   seq2seq/decoder_en/attention/filter_feats41:0 (51, 1, 1, 1)
01/02 16:22:34   seq2seq/decoder_en/attention/U_feats41:0 (1, 256)
01/02 16:22:34   seq2seq/decoder_en/attention/Linear/Matrix:0 (1024, 256)
01/02 16:22:34   seq2seq/decoder_en/attention/Linear/Bias:0 (256,)
01/02 16:22:34   seq2seq/decoder_en/attention/W_feats41:0 (256, 256)
01/02 16:22:34   seq2seq/decoder_en/attention/V_feats41:0 (256,)
01/02 16:22:34   seq2seq/decoder_en/attention_output_projection/Linear/Matrix:0 (512, 124)
01/02 16:22:34   seq2seq/decoder_en/attention_output_projection/Linear/Bias:0 (124,)
01/02 16:22:34   seq2seq/beta1_power:0 ()
01/02 16:22:34   seq2seq/beta2_power:0 ()
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_0/Matrix/Adam:0 (41, 256)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_0/Matrix/Adam_1:0 (41, 256)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_0/Bias/Adam:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_0/Bias/Adam_1:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_1/Matrix/Adam:0 (256, 256)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_1/Matrix/Adam_1:0 (256, 256)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_1/Bias/Adam:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/input_layer_1/Bias/Adam_1:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Matrix/Adam:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Matrix/Adam_1:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_0/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Matrix/Adam:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Matrix/Adam_1:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_0/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Matrix/Adam:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Matrix/Adam_1:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_1/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Matrix/Adam:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Matrix/Adam_1:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_1/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Matrix/Adam:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Matrix/Adam_1:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_FW_2/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Matrix/Adam:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Matrix/Adam_1:0 (768, 1024)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/MultiBiRNN_BW_2/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/bidir_projection/Matrix/Adam:0 (512, 256)
01/02 16:22:34   seq2seq/seq2seq/multi_encoder/feats41/bidir_projection/Matrix/Adam_1:0 (512, 256)
01/02 16:22:34   seq2seq/seq2seq/embedding_en/Adam:0 (124, 256)
01/02 16:22:34   seq2seq/seq2seq/embedding_en/Adam_1:0 (124, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/initial_state_projection/Matrix/Adam:0 (1536, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/initial_state_projection/Matrix/Adam_1:0 (1536, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Matrix/Adam:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Matrix/Adam_1:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Matrix/Adam:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Matrix/Adam_1:0 (512, 1024)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Bias/Adam:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/MultiRNNCell/Cell1/BasicLSTMCell/Linear/Bias/Adam_1:0 (1024,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/filter_feats41/Adam:0 (51, 1, 1, 1)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/filter_feats41/Adam_1:0 (51, 1, 1, 1)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/U_feats41/Adam:0 (1, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/U_feats41/Adam_1:0 (1, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/Linear/Matrix/Adam:0 (1024, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/Linear/Matrix/Adam_1:0 (1024, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/Linear/Bias/Adam:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/Linear/Bias/Adam_1:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/W_feats41/Adam:0 (256, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/W_feats41/Adam_1:0 (256, 256)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/V_feats41/Adam:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention/V_feats41/Adam_1:0 (256,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention_output_projection/Linear/Matrix/Adam:0 (512, 124)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention_output_projection/Linear/Matrix/Adam_1:0 (512, 124)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention_output_projection/Linear/Bias/Adam:0 (124,)
01/02 16:22:34   seq2seq/seq2seq/decoder_en/attention_output_projection/Linear/Bias/Adam_1:0 (124,)
01/02 16:22:40 reading training and development data
01/02 16:22:40 reading training data
01/02 16:22:40 files: experiments/ted_speech/data/train.feats41 experiments/ted_speech/data/train.en
01/02 16:22:40 size: 16
01/02 16:22:40 reading development data
01/02 16:22:40 files: experiments/ted_speech/data/dev.feats41 experiments/ted_speech/data/dev.en
01/02 16:22:40 size: 16
01/02 16:22:40 starting training
01/02 16:22:46 main step 1 learning rate 0.0010 step-time 6.05 perplexity 126.15
01/02 16:22:52   eval: perplexity 110.55
01/02 16:22:52 creating directory experiments/ted_speech/baseline/checkpoints
01/02 16:22:52 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:22:52 finished saving model
01/02 16:22:52 starting decoding
01/02 16:23:14 main score=0.0 penalty=1.0 ratio=1.681
01/02 16:23:19 main step 2 learning rate 0.0010 step-time 4.74 perplexity 120.59
01/02 16:23:25   eval: perplexity 96.91
01/02 16:23:25 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:23:25 finished saving model
01/02 16:23:25 starting decoding
01/02 16:23:47 main score=0.0 penalty=0.0 ratio=0.064
01/02 16:23:51 main step 3 learning rate 0.0010 step-time 4.60 perplexity 103.60
01/02 16:23:57   eval: perplexity 86.61
01/02 16:23:57 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:23:57 finished saving model
01/02 16:23:57 starting decoding
01/02 16:24:19 main score=0.0 penalty=1.0 ratio=1.636
01/02 16:24:23 main step 4 learning rate 0.0010 step-time 4.62 perplexity 90.45
01/02 16:24:29   eval: perplexity 79.76
01/02 16:24:29 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:24:29 finished saving model
01/02 16:24:29 starting decoding
01/02 16:24:51 main score=0.0 penalty=1.0 ratio=1.758
01/02 16:24:56 main step 5 learning rate 0.0010 step-time 4.68 perplexity 97.31
01/02 16:25:01   eval: perplexity 73.20
01/02 16:25:01 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:25:02 finished saving model
01/02 16:25:02 starting decoding
01/02 16:25:23 main score=0.0 penalty=1.0 ratio=1.758
01/02 16:25:28 main step 6 learning rate 0.0010 step-time 4.73 perplexity 120.85
01/02 16:25:34   eval: perplexity 74.24
01/02 16:25:34 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:25:34 finished saving model
01/02 16:25:34 starting decoding
01/02 16:25:56 main score=0.0 penalty=1.0 ratio=1.763
01/02 16:26:00 main step 7 learning rate 0.0010 step-time 4.67 perplexity 117.18
01/02 16:26:06   eval: perplexity 78.49
01/02 16:26:06 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:26:06 finished saving model
01/02 16:26:06 starting decoding
01/02 16:26:28 main score=0.0 penalty=1.0 ratio=1.763
01/02 16:26:33 main step 8 learning rate 0.0010 step-time 4.73 perplexity 96.64
01/02 16:26:38   eval: perplexity 85.84
01/02 16:26:38 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:26:39 finished saving model
01/02 16:26:39 starting decoding
01/02 16:27:00 main score=0.0 penalty=1.0 ratio=1.758
01/02 16:27:05 main step 9 learning rate 0.0010 step-time 4.44 perplexity 79.67
01/02 16:27:11   eval: perplexity 82.70
01/02 16:27:11 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:27:11 finished saving model
01/02 16:27:11 starting decoding
01/02 16:27:33 main score=0.0 penalty=1.0 ratio=1.758
01/02 16:27:37 main step 10 learning rate 0.0010 step-time 4.64 perplexity 96.64
01/02 16:27:43   eval: perplexity 73.35
01/02 16:27:43 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:27:43 finished saving model
01/02 16:27:43 starting decoding
01/02 16:28:05 main score=0.0 penalty=0.996 ratio=0.996
01/02 16:28:10 main step 11 learning rate 0.0010 step-time 4.72 perplexity 72.87
01/02 16:28:15   eval: perplexity 68.32
01/02 16:28:15 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:28:16 finished saving model
01/02 16:28:16 starting decoding
01/02 16:28:37 main score=0.0 penalty=0.43 ratio=0.542
01/02 16:28:42 main step 12 learning rate 0.0010 step-time 4.62 perplexity 54.57
01/02 16:28:47   eval: perplexity 65.28
01/02 16:28:47 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:28:48 finished saving model
01/02 16:28:48 starting decoding
01/02 16:29:09 main score=0.0 penalty=0.142 ratio=0.339
01/02 16:29:14 main step 13 learning rate 0.0010 step-time 4.61 perplexity 74.28
01/02 16:29:20   eval: perplexity 65.80
01/02 16:29:20 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:29:20 finished saving model
01/02 16:29:20 starting decoding
01/02 16:29:42 main score=0.0 penalty=0.068 ratio=0.271
01/02 16:29:46 main step 14 learning rate 0.0010 step-time 4.55 perplexity 35.04
01/02 16:29:52   eval: perplexity 66.51
01/02 16:29:52 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:29:52 finished saving model
01/02 16:29:52 starting decoding
01/02 16:30:14 main score=0.0 penalty=0.424 ratio=0.538
01/02 16:30:18 main step 15 learning rate 0.0010 step-time 4.67 perplexity 111.24
01/02 16:30:24   eval: perplexity 64.38
01/02 16:30:24 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:30:25 finished saving model
01/02 16:30:25 starting decoding
01/02 16:30:46 main score=0.0 penalty=0.706 ratio=0.742
01/02 16:30:51 main step 16 learning rate 0.0010 step-time 4.72 perplexity 131.77
01/02 16:30:56   eval: perplexity 62.51
01/02 16:30:56 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:30:57 finished saving model
01/02 16:30:57 starting decoding
01/02 16:31:18 main score=0.0 penalty=0.805 ratio=0.822
01/02 16:31:23 main step 17 learning rate 0.0010 step-time 4.50 perplexity 59.75
01/02 16:31:28   eval: perplexity 60.85
01/02 16:31:28 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:31:29 finished saving model
01/02 16:31:29 starting decoding
01/02 16:31:50 main score=0.0 penalty=0.869 ratio=0.877
01/02 16:31:55 main step 18 learning rate 0.0010 step-time 4.61 perplexity 84.76
01/02 16:32:00   eval: perplexity 58.89
01/02 16:32:00 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:32:01 finished saving model
01/02 16:32:01 starting decoding
01/02 16:32:22 main score=0.0 penalty=0.869 ratio=0.877
01/02 16:32:27 main step 19 learning rate 0.0010 step-time 4.52 perplexity 59.42
01/02 16:32:33   eval: perplexity 61.06
01/02 16:32:33 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:32:33 finished saving model
01/02 16:32:33 starting decoding
01/02 16:32:54 main score=0.0 penalty=0.79 ratio=0.809
01/02 16:32:59 main step 20 learning rate 0.0010 step-time 4.56 perplexity 104.71
01/02 16:33:05   eval: perplexity 65.98
01/02 16:33:05 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:33:05 finished saving model
01/02 16:33:05 starting decoding
01/02 16:33:27 main score=0.0 penalty=0.706 ratio=0.742
01/02 16:33:31 main step 21 learning rate 0.0010 step-time 4.53 perplexity 75.72
01/02 16:33:37   eval: perplexity 67.06
01/02 16:33:37 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:33:37 finished saving model
01/02 16:33:37 starting decoding
01/02 16:33:59 main score=0.0 penalty=0.616 ratio=0.674
01/02 16:34:03 main step 22 learning rate 0.0010 step-time 4.63 perplexity 80.95
01/02 16:34:09   eval: perplexity 63.86
01/02 16:34:09 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:34:10 finished saving model
01/02 16:34:10 starting decoding
01/02 16:34:31 main score=0.0 penalty=0.616 ratio=0.674
01/02 16:34:36 main step 23 learning rate 0.0010 step-time 4.59 perplexity 51.83
01/02 16:34:41   eval: perplexity 60.04
01/02 16:34:41 saving model to experiments/ted_speech/baseline/checkpoints
01/02 16:34:42 finished saving model
01/02 16:34:42 starting decoding
01/02 16:35:02 exiting...
01/02 16:35:02 saving model to experiments/ted_speech/baseline/checkpoints
